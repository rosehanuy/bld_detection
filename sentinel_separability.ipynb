{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "root = Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d56e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def jm_per_band(x_class1, x_class2, n_points=200):\n",
    "    x1 = np.asarray(x_class1)\n",
    "    x2 = np.asarray(x_class2)\n",
    "    x1 = x1[~np.isnan(x1)]\n",
    "    x2 = x2[~np.isnan(x2)]\n",
    "\n",
    "    if len(x1) < 5 or len(x2) < 5:\n",
    "        return np.nan\n",
    "  \n",
    "    #estimate pdfs for both classes\n",
    "    kde1 = gaussian_kde(x1)\n",
    "    kde2 = gaussian_kde(x2)\n",
    "\n",
    "    #get the min/max range for both classes\n",
    "    lo = min(x1.min(),x2.min())\n",
    "    hi = max(x1.max(),x2.max())\n",
    "    x_linspace = np.linspace(lo, hi, n_points)\n",
    "\n",
    "    #evaluate estimated pdfs for this range\n",
    "    u = kde1(x_linspace)\n",
    "    v = kde2(x_linspace)\n",
    "\n",
    "    # Normalize to integrate to 1\n",
    "    u /= np.trapezoid(u, x_linspace)\n",
    "    v /= np.trapezoid(v, x_linspace)\n",
    "\n",
    "    # Bhattacharyya distance\n",
    "    bc = np.trapezoid(np.sqrt(u * v), x_linspace)\n",
    "    B = -np.log(bc + 1e-15)\n",
    "\n",
    "    # JM distance\n",
    "    J = 2 * (1 - np.exp(-B))\n",
    "     \n",
    "    return J\n",
    "\n",
    "def get_fad_classes(df,year,fad):\n",
    "    if year == 'allyears':\n",
    "        class1_df = df.loc[df['FAD'].str.contains(fad),:]\n",
    "        class2_df = df.loc[~df['FAD'].str.contains(fad),:]\n",
    "    else:\n",
    "        class1_df = df.loc[(df['FAD'].str.contains(fad))&(df['year'].isin(year)),:]\n",
    "        class2_df = df.loc[(~df['FAD'].str.contains(fad))&(df['year'].isin(year)),:]\n",
    "    \n",
    "    return class1_df, class2_df\n",
    "\n",
    "\n",
    "def get_classes(df,year,class1,class2):\n",
    "    if year == 'allyears':\n",
    "        class1_df = df.loc[(df['status'].isin(class1)),:]\n",
    "        class2_df = df.loc[(df['status']==class2),:]\n",
    "    else:\n",
    "        class1_df = df.loc[(df['status'].isin(class1))&(df['year'].isin(year)),:]\n",
    "        class2_df = df.loc[(df['status']==class2)&(df['year'].isin(year)),:]\n",
    "    \n",
    "    return class1_df, class2_df\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b2a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(root / 'figs' / 'harvard' / 'jm_distance_plots',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215bfba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pertree_df = pd.read_csv(root / 'data' / 'harvard' / 'per_tree_average_monthly_spectra_and_health_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c76f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pertree_df['BLD'] = pertree_df['BLD'].replace(np.nan,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81522e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "beech_tags = pertree_df.loc[pertree_df['year']==2025,'StemTag'].unique()\n",
    "beechonly_df = pertree_df.loc[pertree_df['StemTag'].isin(beech_tags),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fad_pertree_df = pertree_df.loc[~pertree_df['FAD'].isna(),:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f147e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "beech_pixels = perpixel_df.loc[perpixel_df['StemTag'].isin(beech_tags)]\n",
    "plot_df = beech_pixels.drop_duplicates(['row','col','StemTag'])\n",
    "\n",
    "ax = plot_df['frac'].hist()\n",
    "\n",
    "plt.xlabel('% of Pixel Covered by Beech Crown Polygon')\n",
    "plt.ylabel('Num Pixels')\n",
    "plt.title('Beech Canopy Coverage per Pixel')\n",
    "\n",
    "plt.savefig(root / 'figs'/ 'harvard' / 'histogram_beechonly_canopy_coverage_per_pixel.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a35aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_cols = [x for x in pertree_df.columns if '_B' in x]\n",
    "\n",
    "\n",
    "# year = [2023,2025]\n",
    "# class1 = ['AU']\n",
    "# class2 = 'A'\n",
    "\n",
    "# class1_df, class2_df = get_classes(pertree_df,year=year,class1=class1,class2=class2)\n",
    "\n",
    "title = 'Beech Only'\n",
    "filename = 'beechonly'\n",
    "\n",
    "# year = [2025]\n",
    "# class1 = 'LF'\n",
    "# class2 = 'No LF'\n",
    "# fad = 'LF'\n",
    "# \n",
    "# class1_df, class2_df = get_fad_classes(fad_pertree_df,year=year,fad='DF')\n",
    "\n",
    "########################################\n",
    "year = [2023,2025]\n",
    "class1 = 'BLD'\n",
    "class2 = 'No BLD'\n",
    "\n",
    "def get_bld_classes(df,year):\n",
    "    if year == 'allyears':\n",
    "        class1_df = df.loc[df['BLD']==1.0,:]\n",
    "        class2_df = df.loc[(df['BLD']==0.0),:]\n",
    "    else:\n",
    "        class1_df = df.loc[(df['BLD']==1.0)&(df['year'].isin(year)),:]\n",
    "        class2_df = df.loc[(df['BLD']==0.0)&(df['year'].isin(year)),:]\n",
    "    \n",
    "    return class1_df, class2_df\n",
    "\n",
    "class1_df, class2_df = get_bld_classes(beechonly_df,year=year)\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "class1_n = len(class1_df)\n",
    "class2_n = len(class2_df)\n",
    "\n",
    "jm_values = {}\n",
    "\n",
    "for j in j_cols:\n",
    "\n",
    "    jm = jm_per_band(x_class1=class1_df[j],x_class2=class2_df[j])\n",
    "\n",
    "    jm_values[j] = jm\n",
    "\n",
    "\n",
    "wide_df = pd.DataFrame(jm_values,index=[0],columns=j_cols)\n",
    "long_df = wide_df.T.reset_index()\n",
    "long_df = long_df.rename(columns={'index':'month_band',0:'jm'})\n",
    "long_df[['month','band']] = long_df['month_band'].str.split('_', expand=True)\n",
    "pivot_df = long_df.pivot(index='month',columns='band',values='jm')\n",
    "pivot_df = pivot_df.rename(columns={'B02':'Blue','B03':'Green','B04':'Red','B05':'Red Edge 1','B06':'Red Edge 2','B07':'Red Edge 3','B08':'NIR','B11':'SW1','B12':'SW2','B8A': 'NIR narrow'})\n",
    "\n",
    "order = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n",
    "         \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "pivot_df = pivot_df.reindex(order)\n",
    "\n",
    "# drop nan columns\n",
    "#pivot_df = pivot_df.dropna(axis=0)\n",
    "\n",
    "pivot_df = pivot_df.astype('float')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.heatmap(pivot_df, annot=True, cmap='Reds', fmt='.2f',vmin=0,vmax=1.5)\n",
    "\n",
    "plt.xlabel('Band',fontsize=12)\n",
    "plt.ylabel('Month',fontsize=12)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.title(f\"JM Distance, {title}: {year}\",pad=10,fontsize=14,loc='right')\n",
    "\n",
    "plt.text(-0.12,1.02,f\"Class 1: {class1}  (n={class1_n})\\nClass 2: {class2}  (n={class2_n})\",ha='left', va='bottom', fontsize=10, transform=plt.gca().transAxes)\n",
    "\n",
    "plt.savefig(root / 'figs' / 'harvard' / 'jm_distance_plots' / f'jmdistance_heatmap_weightedfracs_{filename}_{year}_{class1}_{class2}.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f292510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def lda_spectral(by_tree_df, band_cols, label_col='BLD'):\n",
    "    X = by_tree_df[band_cols].values\n",
    "    y = by_tree_df[label_col].values\n",
    "\n",
    "    lda = LDA(n_components=1)\n",
    "    Z = lda.fit_transform(X, y)\n",
    "\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.hist(Z[y==1], bins=20, alpha=0.6, label='BLD', color='red')\n",
    "    plt.hist(Z[y==0], bins=20, alpha=0.6, label='No BLD', color='blue')\n",
    "    plt.title(\"LDA Discriminant Projection\")\n",
    "    plt.xlabel(\"LDA Score\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.show()\n",
    "\n",
    "    # Band importance (loadings)\n",
    "    loadings = pd.Series(lda.coef_[0], index=band_cols)\n",
    "    loadings = loadings.sort_values(key=np.abs, ascending=False)\n",
    "\n",
    "    return lda, Z, loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c8fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_cols = [x for x in pertree_df.columns if any(y in x for y in ['Jun_B','Jul_B','Aug_B','Sep_B'])]\n",
    "label_col = ['BLD']\n",
    "\n",
    "pertree_2523 = pertree_df.loc[pertree_df['year'].isin([2025,2023]),band_cols + label_col].copy()\n",
    "#pertree_2524['BLD'] = pertree_2524['BLD'].replace(np.nan,0.0)\n",
    "pertree_2523 = pertree_2523.dropna(subset=band_cols + label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda, z, loadings = lda_spectral(pertree_2523,band_cols=band_cols)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
