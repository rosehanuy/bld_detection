{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import h5netcdf\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import neonutilities as neon\n",
    "import requests\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from rasterio.transform import rowcol\n",
    "from shapely import box\n",
    "from rasterio.features import rasterize\n",
    "from affine import Affine\n",
    "\n",
    "root = Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b4da9",
   "metadata": {},
   "source": [
    "### Download HS data from NEON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09d8b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provisional NEON data are included. To exclude provisional data, use input parameter include_provisional=False.\n",
      "Downloading 3 NEON data files totaling approximately 1.3 GB\n",
      "\n",
      "100%|██████████| 3/3 [00:37<00:00, 12.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# get api token stored in txt file\n",
    "with open('neon_token.txt','r') as f:\n",
    "    token = f.readline()\n",
    "\n",
    "# read in geodataframe to define AOI\n",
    "crowns = gpd.read_file(root / 'data' / 'harvard' / 'all_tree_crown_polys.gpkg')\n",
    "crowns = crowns.to_crs(32618)\n",
    "\n",
    "# set query parameters\n",
    "easting = list(crowns.get_coordinates()['x'].astype('int').values)\n",
    "northing = list(crowns.get_coordinates()['y'].astype('int').values)\n",
    "savepath = root / 'data' / 'harvard' / 'hyperspectral'\n",
    "year = 2025\n",
    "site = 'HARV'\n",
    "\n",
    "# run handy dandy neon utility function to download data\n",
    "neon.by_tile_aop(dpid=\"DP3.30006.002\",  #\"DP3.30006.001\" for data prior to 2022\n",
    "\t\tsite=site,\n",
    "\t\tyear=year,\n",
    "\t\teasting=easting,\n",
    "\t\tnorthing=northing,\n",
    "\t\tsavepath='c:/Users/roseh/My Drive/harvard_forest/data/harvard/hyperspectral',\n",
    "        include_provisional=True,\n",
    "\t\ttoken=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f6b084",
   "metadata": {},
   "source": [
    "### Extract tree spectral signatures from NEON H5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e3389",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_tile_gdf(tile_dir):\n",
    "    all_files = [f for f in os.scandir(tile_dir) if f.is_file() and f.path.endswith('.h5')]\n",
    "\n",
    "    polygons = []\n",
    "    file_west_bounds = []\n",
    "    file_north_bounds = []\n",
    "\n",
    "    for f in all_files:\n",
    "        split_name = f.path.split('_')\n",
    "        min_x, min_y = int(split_name[-4]), int(split_name[-3]) # get origin from file name\n",
    "        max_x, max_y = min_x + 1000, min_y + 1000\n",
    "        file_west_bounds.append(min_x)\n",
    "        file_north_bounds.append(max_y)\n",
    "        tile_poly = box(min_x, min_y, max_x, max_y)\n",
    "        polygons.append(tile_poly)\n",
    "\n",
    "    tiles = gpd.GeoDataFrame(\n",
    "        data={\n",
    "                'filepath': all_files,\n",
    "                'file_west_bound': file_west_bounds,\n",
    "                'file_north_bound': file_north_bounds\n",
    "            }, \n",
    "        geometry=polygons, \n",
    "        crs=epsg)\n",
    "    \n",
    "    return tiles\n",
    "\n",
    "def get_hs_filter(bands):\n",
    "        # method from https://github.com/atalbanese/NEON_Hyperspectral/blob/main/annotation.py\n",
    "        hs_filters = [[410,1320],[1450,1800],[2050,2475]]\n",
    "        mask_list = [(bands>=lmin) & (bands<=lmax) for lmin, lmax in hs_filters]\n",
    "        band_mask = np.logical_or.reduce(mask_list)\n",
    "        idxs = np.where(band_mask)[0]\n",
    "        return idxs\n",
    "\n",
    "## loop over tiles, find crown polygons that overlap and extract tree spectra for those polygons\n",
    "def make_tree_spectra_df(crowns, tiles, scale = 1.0):\n",
    "    spectra_dfs_list = []\n",
    "\n",
    "    for ix, tile in tiles.iterrows():\n",
    "        \n",
    "        # get crown polys that intersect this tile\n",
    "        crowns_in_tile = crowns[crowns.intersects(tile.geometry)]\n",
    "        if crowns_in_tile.empty:\n",
    "            print(f'no tree crowns found in tile {ix}')\n",
    "            continue\n",
    "\n",
    "        min_x, min_y, max_x, max_y = crowns_in_tile.total_bounds   \n",
    "\n",
    "        transform = Affine.translation(tile['file_west_bound'], tile['file_north_bound']) * Affine.scale(scale, -scale)\n",
    "        row_0, col_0 = rowcol(transform,min_x,max_y) # upper left\n",
    "        row_1, col_1 = rowcol(transform,max_x,min_y) # lower right\n",
    "        # sort to avoid silent rounding errors\n",
    "        row_0, row_1 = sorted((row_0,row_1))\n",
    "        col_0, col_1 = sorted((col_0,col_1))\n",
    "        \n",
    "        hs_file = h5py.File(tile['filepath'].path, 'r')\n",
    "\n",
    "        rows_full, cols_full, _ = hs_file['HARV'][\"Reflectance\"][\"Reflectance_Data\"].shape\n",
    "        \n",
    "        # so much numpy indexing - making sure we are inside the tile bounds still\n",
    "        row_start = max(0, min(row_0,rows_full-1))\n",
    "        row_stop = max(0,min(row_1+1,rows_full))\n",
    "        col_start = max(0, min(col_0,cols_full-1))\n",
    "        col_stop = max(0,min(col_1+1,cols_full))\n",
    "\n",
    "        bands = hs_file['HARV'][\"Reflectance\"][\"Metadata\"]['Spectral_Data']['Wavelength'][:]\n",
    "        hs_filter = get_hs_filter(bands)\n",
    "        bands = bands[hs_filter]\n",
    "\n",
    "        hs_grab = hs_file['HARV'][\"Reflectance\"][\"Reflectance_Data\"][row_start:row_stop,col_start:col_stop,hs_filter]/10000\n",
    "        hs_grab = hs_grab.astype(np.float32)\n",
    "        hs_file.close()\n",
    "\n",
    "        rows,cols, _ = hs_grab.shape\n",
    "    \n",
    "        # new transform for cropped raster\n",
    "        crop_transform = Affine.translation(tile['file_west_bound'] + col_0 * scale, tile['file_north_bound'] - row_0 * scale)* Affine.scale(scale, -scale)\n",
    "        # rasterize stemtags to select tree spectra\n",
    "        shapes = list(zip(crowns_in_tile.geometry,crowns_in_tile['StemTag'].astype(int)))\n",
    "        stemtag_raster = rasterize(\n",
    "            shapes,\n",
    "            out_shape=(rows,cols),\n",
    "            transform=crop_transform,\n",
    "            fill=0,\n",
    "            all_touched=False,\n",
    "            dtype=\"int32\",\n",
    "        )\n",
    "\n",
    "        row_idx, col_idx = np.where(stemtag_raster > 0)\n",
    "        if row_idx.size == 0:\n",
    "            continue\n",
    "        \n",
    "        stemtags = stemtag_raster[row_idx,col_idx]\n",
    "        canopy_spectra = hs_grab[row_idx,col_idx,:]\n",
    "\n",
    "        spec_df = pd.DataFrame(canopy_spectra,columns=bands)\n",
    "        spec_df['StemTag'] = stemtags\n",
    "        spec_df['row'] = row_idx\n",
    "        spec_df['col'] = col_idx\n",
    "        \n",
    "        spectra_dfs_list.append(spec_df)\n",
    "\n",
    "\n",
    "    all_spectra = pd.concat(spectra_dfs_list,ignore_index=True)\n",
    "\n",
    "    return all_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of neon h5 file\n",
    "tile_dir = root / 'data' / 'harvard' / 'hyperspectral'\n",
    "\n",
    "tiles = make_tile_gdf(tile_dir=tile_dir)\n",
    "\n",
    "all_spectra = make_tree_spectra_df(crowns=crowns,tiles=tiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a11af051",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spectra.to_csv(root / 'data' / 'harvard' / 'hyperspectral' / '2025_all_tree_spectra.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf2-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
